============================= test session starts ==============================
platform darwin -- Python 3.13.5, pytest-9.0.2, pluggy-1.6.0
rootdir: /Users/soumyadebtripathy/crypto-ai-decision-system
plugins: anyio-4.11.0, asyncio-1.3.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collected 31 items

test_alpha_upgrade.py .                                                  [  3%]
test_plot.py .                                                           [  6%]
test_risk_hardening.py .                                                 [  9%]
tests/test_correlation_guard.py ..                                       [ 16%]
tests/test_execution_v22.py ...                                          [ 25%]
tests/test_l2_pipeline.py ...                                            [ 35%]
tests/test_loss_guard.py .                                               [ 38%]
tests/test_ml_v18.py ...F                                                [ 51%]
tests/test_portfolio_env.py FFF                                          [ 61%]
tests/test_portfolio_risk.py ...                                         [ 70%]
tests/test_ppo_memory.py FF                                              [ 77%]
tests/test_regime_v21.py .                                               [ 80%]
tests/test_sentiment_fallback.py ..                                      [ 87%]
tests/test_v24_alpha.py ....                                             [100%]

=================================== FAILURES ===================================
______________________ TestMLv18.test_uncertainty_engine _______________________

self = <test_ml_v18.TestMLv18 testMethod=test_uncertainty_engine>

    def test_uncertainty_engine(self):
        print("\nTesting Uncertainty Engine (MC Dropout)...")
        # Mock model
        model = torch.nn.Linear(10, 1)
        eng = UncertaintyEngine(model, n_passes=5)
        x = torch.randn(1, 10)
        mean, epi, ale = eng.predict_with_uncertainty(x)
        print(f"Mean: {mean:.4f}, Epistemic: {epi:.4f}")
        self.assertIsInstance(mean, float)
>       self.assertGreaterEqual(epi, 0.0)
E       AssertionError: nan not greater than or equal to 0.0

tests/test_ml_v18.py:23: AssertionError
----------------------------- Captured stdout call -----------------------------

Testing Uncertainty Engine (MC Dropout)...
Mean: nan, Epistemic: nan
_____________________ TestPortfolioEnv.test_agent_forward ______________________

self = <test_portfolio_env.TestPortfolioEnv testMethod=test_agent_forward>

    def test_agent_forward(self):
        obs = self.env.reset()
>       action, _ = self.agent.select_action(obs)
        ^^^^^^^^^
E       ValueError: not enough values to unpack (expected 2, got 0)

tests/test_portfolio_env.py:45: ValueError
_______________________ TestPortfolioEnv.test_dimensions _______________________

self = <test_portfolio_env.TestPortfolioEnv testMethod=test_dimensions>

    def setUp(self):
        self.assets = ["BTC", "ETH", "SOL"]
        self.env = PortfolioEnv(
            self.assets, initial_balance=10000, transaction_cost_bps=5.0
        )
>       self.agent = PPOPortfolioAgent(
            state_dim=self.env.state_dim, action_dim=self.env.action_dim
        )

tests/test_portfolio_env.py:15: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1169: in __call__
    return self._mock_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1173: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='4791315360'>, args = ()
kwargs = {'action_dim': 4, 'state_dim': 10}
effect = <tuple_iterator object at 0x11d9965c0>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
                         ^^^^^^^^^^^^
E               StopIteration

/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1230: StopIteration
_____________________ TestPortfolioEnv.test_step_mechanics _____________________

self = <test_portfolio_env.TestPortfolioEnv testMethod=test_step_mechanics>

    def setUp(self):
        self.assets = ["BTC", "ETH", "SOL"]
        self.env = PortfolioEnv(
            self.assets, initial_balance=10000, transaction_cost_bps=5.0
        )
>       self.agent = PPOPortfolioAgent(
            state_dim=self.env.state_dim, action_dim=self.env.action_dim
        )

tests/test_portfolio_env.py:15: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1169: in __call__
    return self._mock_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1173: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='4791315360'>, args = ()
kwargs = {'action_dim': 4, 'state_dim': 10}
effect = <tuple_iterator object at 0x11d9965c0>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
                         ^^^^^^^^^^^^
E               StopIteration

/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1230: StopIteration
_____________________ TestPPOMemory.test_selective_storage _____________________

self = <test_ppo_memory.TestPPOMemory testMethod=test_selective_storage>

    def setUp(self):
        # Setup the mock environment for each test
        self.torch_mock = MagicMock()
        self.torch_mock.Tensor = MagicMock
        self.torch_mock.tensor = lambda x, **kwargs: x # Identity for values
        self.torch_mock.norm.return_value = 1.0
    
        # Apply patch
        # We need nn.Module to be a class for inheritance to work
        nn_mock = MagicMock()
        nn_mock.Module = type('Module', (), {}) # Create a dummy class
    
        self.patcher = patch.dict(sys.modules, {
            "torch": self.torch_mock,
            "torch.nn": nn_mock,
            "torch.optim": MagicMock()
        })
        self.patcher.start()
    
        # Import modules inside the patched environment
        # We need to ensure we re-import or import fresh
>       import src.models.portfolio_rl.ppo_agent as ppo_module
E       ImportError: cannot import name 'portfolio_rl' from 'src.models' (unknown location)

tests/test_ppo_memory.py:29: ImportError
_____________________ TestPPOMemory.test_weighted_sampling _____________________

self = <test_ppo_memory.TestPPOMemory testMethod=test_weighted_sampling>

    def setUp(self):
        # Setup the mock environment for each test
        self.torch_mock = MagicMock()
        self.torch_mock.Tensor = MagicMock
        self.torch_mock.tensor = lambda x, **kwargs: x # Identity for values
        self.torch_mock.norm.return_value = 1.0
    
        # Apply patch
        # We need nn.Module to be a class for inheritance to work
        nn_mock = MagicMock()
        nn_mock.Module = type('Module', (), {}) # Create a dummy class
    
        self.patcher = patch.dict(sys.modules, {
            "torch": self.torch_mock,
            "torch.nn": nn_mock,
            "torch.optim": MagicMock()
        })
        self.patcher.start()
    
        # Import modules inside the patched environment
        # We need to ensure we re-import or import fresh
>       import src.models.portfolio_rl.ppo_agent as ppo_module
E       ImportError: cannot import name 'portfolio_rl' from 'src.models' (unknown location)

tests/test_ppo_memory.py:29: ImportError
=============================== warnings summary ===============================
test_alpha_upgrade.py::test_alpha_upgrade
  /Users/soumyadebtripathy/crypto-ai-decision-system/test_alpha_upgrade.py:45: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.
    dates = pd.date_range(start="2024-01-01", periods=100, freq="H")

tests/test_ml_v18.py::TestMLv18::test_uncertainty_engine
  /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.
    return _methods._mean(a, axis=axis, dtype=dtype,

tests/test_ml_v18.py::TestMLv18::test_uncertainty_engine
  /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/numpy/_core/_methods.py:144: RuntimeWarning: invalid value encountered in scalar divide
    ret = ret.dtype.type(ret / rcount)

tests/test_ml_v18.py::TestMLv18::test_uncertainty_engine
  /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:4268: RuntimeWarning: Degrees of freedom <= 0 for slice
    return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,

tests/test_ml_v18.py::TestMLv18::test_uncertainty_engine
  /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/numpy/_core/_methods.py:180: RuntimeWarning: invalid value encountered in divide
    arrmean = um.true_divide(arrmean, div, out=arrmean,

tests/test_ml_v18.py::TestMLv18::test_uncertainty_engine
  /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/numpy/_core/_methods.py:214: RuntimeWarning: invalid value encountered in scalar divide
    ret = ret.dtype.type(ret / rcount)

tests/test_v24_alpha.py::TestV24Alpha::test_calibration
  /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.
    warnings.warn(

tests/test_v24_alpha.py::TestV24Alpha::test_meta_failure
  /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/test_ml_v18.py::TestMLv18::test_uncertainty_engine - AssertionEr...
FAILED tests/test_portfolio_env.py::TestPortfolioEnv::test_agent_forward - Va...
FAILED tests/test_portfolio_env.py::TestPortfolioEnv::test_dimensions - StopI...
FAILED tests/test_portfolio_env.py::TestPortfolioEnv::test_step_mechanics - S...
FAILED tests/test_ppo_memory.py::TestPPOMemory::test_selective_storage - Impo...
FAILED tests/test_ppo_memory.py::TestPPOMemory::test_weighted_sampling - Impo...
=================== 6 failed, 25 passed, 8 warnings in 1.74s ===================

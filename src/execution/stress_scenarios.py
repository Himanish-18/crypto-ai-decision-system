import json
import logging
from pathlib import Path

import pandas as pd

from src.execution.backtest import BacktestConfig, Backtester

# Setup Logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("stress_scenarios")

PROJECT_ROOT = Path(__file__).resolve().parents[2]
DATA_DIR = PROJECT_ROOT / "data"
MODELS_DIR = DATA_DIR / "models"
FEATURES_FILE = DATA_DIR / "features" / "alpha_features.parquet"
OUTPUT_FILE = PROJECT_ROOT / "reports" / "strategy_stress_results.md"
OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)


def run_scenario(name: str, config: BacktestConfig):
    logger.info(f"ðŸš€ Running Scenario: {name}")

    backtester = Backtester(
        model_path=MODELS_DIR / "multifactor_model.pkl",
        scaler_path=MODELS_DIR
        / "scaler_v1.pkl",  # Unused by MF Model but required by init
        features_path=FEATURES_FILE,
        config=config,
    )

    backtester.load_artifacts()
    backtester.prepare_data()
    backtester.run_backtest()
    metrics = backtester.calculate_metrics()
    return metrics


def main():
    scenarios = {
        "Base Case": BacktestConfig(
            fee_rate=0.00075, base_slippage=0.0005, slippage_model="fixed", gap_prob=0.0
        ),
        "High Slippage (2x + Dynamic)": BacktestConfig(
            fee_rate=0.00075,
            base_slippage=0.0010,  # 2x Base
            slippage_model="dynamic_atr",  # And Dynamic
            gap_prob=0.0,
        ),
        "High Fees (3x)": BacktestConfig(
            fee_rate=0.00225, base_slippage=0.0005, gap_prob=0.0  # 3x 0.00075
        ),
        "Gap Risk (1% Gap Event)": BacktestConfig(
            fee_rate=0.00075,
            base_slippage=0.0005,
            gap_prob=0.02,  # 2% chance per candle (approx 1 every 50 hours)
            gap_range=(0.01, 0.03),  # 1-3% gap
        ),
    }

    results = []

    for name, config in scenarios.items():
        m = run_scenario(name, config)
        if not m:
            continue

        results.append(
            {
                "Scenario": name,
                "Profit Factor": f"{m.get('profit_factor', 0):.2f}",
                "Win Rate": f"{m.get('win_rate', 0)*100:.1f}%",
                "Total Return": f"{m.get('total_return', 0)*100:.1f}%",
                "Max Drawdown": f"{m.get('max_drawdown', 0)*100:.1f}%",
                "Trades": m.get("total_trades", 0),
            }
        )

    # Generate Report
    df_res = pd.DataFrame(results)

    # Manual Markdown Table
    md_table = "| Scenario | Profit Factor | Win Rate | Total Return | Max Drawdown | Trades |\n"
    md_table += "|---|---|---|---|---|---|\n"
    for r in results:
        md_table += f"| {r['Scenario']} | {r['Profit Factor']} | {r['Win Rate']} | {r['Total Return']} | {r['Max Drawdown']} | {r['Trades']} |\n"

    markdown = f"""# Strategy Hardening Stress Test Results

## Overview
Comparison of strategy performance under adverse conditions after implementing Hardening measures (Gap-Safe Sizing, Dynamic Slippage, Regime Filtering).

## Results Table
{md_table}

## Key Observations
- **Gap Risk**: Previous Profit Factor was 0.08. Target > 0.5.
- **Slippage**: Dynamic slippage impacts high-volatility trades.

*Generated by src/execution/stress_scenarios.py*
"""

    with open(OUTPUT_FILE, "w") as f:
        f.write(markdown)

    logger.info(f"âœ… Report generated at {OUTPUT_FILE}")
    print(df_res)


if __name__ == "__main__":
    main()
